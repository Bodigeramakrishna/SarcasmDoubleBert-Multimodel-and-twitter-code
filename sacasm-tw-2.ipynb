{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9530136,"sourceType":"datasetVersion","datasetId":5803729},{"sourceId":10493296,"sourceType":"datasetVersion","datasetId":6496907},{"sourceId":10549594,"sourceType":"datasetVersion","datasetId":6527363}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install pandas numpy scikit-learn torch transformers tqdm\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p70LySrA4F91","outputId":"319686c6-b959-4e4a-bc13-bc201aa748d4","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:35:13.516128Z","iopub.execute_input":"2025-04-11T14:35:13.516466Z","iopub.status.idle":"2025-04-11T14:35:22.921176Z","shell.execute_reply.started":"2025-04-11T14:35:13.516425Z","shell.execute_reply":"2025-04-11T14:35:22.920118Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertModel, BertConfig, AdamW, get_linear_schedule_with_warmup\nfrom tqdm import tqdm\n","metadata":{"id":"weW4BTRf4My7","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:35:22.924202Z","iopub.execute_input":"2025-04-11T14:35:22.924974Z","iopub.status.idle":"2025-04-11T14:35:29.003974Z","shell.execute_reply.started":"2025-04-11T14:35:22.924939Z","shell.execute_reply":"2025-04-11T14:35:29.003032Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load the dataset\n# Replace 'your_dataset.csv' with your actual dataset path\ndf = pd.read_csv('/kaggle/input/twitter/train.csv')  # Ensure the file path is correct\n\n# Display basic information\nprint(f\"Total samples: {len(df)}\")\n#df=df[0:10000]\nprint(df.head())\nprint(df.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5IOjlFz-4Pg0","outputId":"0ce0344b-3658-4aac-9e66-5eac758988e2","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:35:29.005209Z","iopub.execute_input":"2025-04-11T14:35:29.006054Z","iopub.status.idle":"2025-04-11T14:35:30.997065Z","shell.execute_reply.started":"2025-04-11T14:35:29.006009Z","shell.execute_reply":"2025-04-11T14:35:30.996153Z"}},"outputs":[{"name":"stdout","text":"Total samples: 1046343\n   Y                                               text\n0  1                                  kinder craft time\n1  0                             i miss my seat partner\n2  1                                             thanks\n3  0                                     we alreay went\n4  1  i don t think chorizo counts in any healthy ea...\n(1046343, 2)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHhpGqDE7VUH","outputId":"52d4e545-8ee1-4864-decd-d63b59bc1bab","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=df.dropna()","metadata":{"id":"Tje_6zk7asxy","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:35:30.998223Z","iopub.execute_input":"2025-04-11T14:35:30.998565Z","iopub.status.idle":"2025-04-11T14:35:31.089776Z","shell.execute_reply.started":"2025-04-11T14:35:30.998538Z","shell.execute_reply":"2025-04-11T14:35:31.089069Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(df)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C-n7StmWbFtf","outputId":"b572329f-efc3-4dba-eb7d-7503b2862c28","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:35:31.090757Z","iopub.execute_input":"2025-04-11T14:35:31.091019Z","iopub.status.idle":"2025-04-11T14:35:31.102247Z","shell.execute_reply.started":"2025-04-11T14:35:31.090993Z","shell.execute_reply":"2025-04-11T14:35:31.101169Z"}},"outputs":[{"name":"stdout","text":"         Y                                               text\n0        1                                  kinder craft time\n1        0                             i miss my seat partner\n2        1                                             thanks\n3        0                                     we alreay went\n4        1  i don t think chorizo counts in any healthy ea...\n...     ..                                                ...\n1046338  0          i don t like being locked out from things\n1046339  1         still got that one packed it yesterday too\n1046340  1  oh if only i had a garden i hardly ever miss h...\n1046341  0  same shit lol sleepy but i need to charge my p...\n1046342  1  dude you ve been quiet miss you can we hang ou...\n\n[1046343 rows x 2 columns]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df['text'] = df['text'].fillna(\"\").astype(str)\nx, xt, y, yt = train_test_split(\n    df['text'].values,\n    df['Y'].values,\n    test_size=0.9,\n    random_state=15,\n    stratify=df['Y'].values\n)\n\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    x,\n    y,\n    test_size=0.3,\n    random_state=25,\n    #stratify=df['y'].values\n)\n","metadata":{"id":"CTHyWUab4PdO","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:35:31.103649Z","iopub.execute_input":"2025-04-11T14:35:31.104027Z","iopub.status.idle":"2025-04-11T14:35:31.715229Z","shell.execute_reply.started":"2025-04-11T14:35:31.103985Z","shell.execute_reply":"2025-04-11T14:35:31.714525Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(train_texts.size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:35:31.717886Z","iopub.execute_input":"2025-04-11T14:35:31.718194Z","iopub.status.idle":"2025-04-11T14:35:31.722873Z","shell.execute_reply.started":"2025-04-11T14:35:31.718164Z","shell.execute_reply":"2025-04-11T14:35:31.722100Z"}},"outputs":[{"name":"stdout","text":"73243\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Initialize BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Define maximum sequence length\nMAX_LEN = 128\n\ndef tokenize_texts(texts, tokenizer, max_len):\n    return tokenizer.batch_encode_plus(\n        texts,\n        add_special_tokens=True,\n        max_length=max_len,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n\n# Tokenize training and validation texts\ntrain_encodings = tokenize_texts(train_texts, tokenizer, MAX_LEN)\nval_encodings = tokenize_texts(val_texts, tokenizer, MAX_LEN)\n","metadata":{"id":"Xs-sbrxw4Pai","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:35:31.723883Z","iopub.execute_input":"2025-04-11T14:35:31.724125Z","iopub.status.idle":"2025-04-11T14:36:10.339106Z","shell.execute_reply.started":"2025-04-11T14:35:31.724099Z","shell.execute_reply":"2025-04-11T14:36:10.338415Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b33f319ea5b4cbaa6ba11c8741d30a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"278dc63a4b274087b597d9c3ec94558e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b772bf5e7844447eb4d95660afbc448e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffe11555096d468ab6b5c3ea33e522cf"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"class SarcasmDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.input_ids = encodings['input_ids']\n        self.attention_mask = encodings['attention_mask']\n        self.labels = torch.tensor(labels)\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': self.input_ids[idx],\n            'attention_mask': self.attention_mask[idx],\n            'labels': self.labels[idx]\n        }\n\n# Create Dataset objects\ntrain_dataset = SarcasmDataset(train_encodings, train_labels)\nval_dataset = SarcasmDataset(val_encodings, val_labels)\n","metadata":{"id":"Vp0KoGsz4PYC","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:36:10.340106Z","iopub.execute_input":"2025-04-11T14:36:10.340378Z","iopub.status.idle":"2025-04-11T14:36:10.357902Z","shell.execute_reply.started":"2025-04-11T14:36:10.340352Z","shell.execute_reply":"2025-04-11T14:36:10.356996Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"BATCH_SIZE = 16\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","metadata":{"id":"vymxoDNm4PVi","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:36:10.359048Z","iopub.execute_input":"2025-04-11T14:36:10.359511Z","iopub.status.idle":"2025-04-11T14:36:10.365568Z","shell.execute_reply.started":"2025-04-11T14:36:10.359471Z","shell.execute_reply":"2025-04-11T14:36:10.364654Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class DoubleBERT(nn.Module):\n    def __init__(self, bert_model_name='bert-base-uncased', num_labels=2):\n        super(DoubleBERT, self).__init__()\n        # First BERT model for embeddings\n        self.bert_encoder = BertModel.from_pretrained(bert_model_name)\n\n        # Second BERT model for classification\n        self.bert_classifier = BertModel.from_pretrained(bert_model_name)\n\n        # Classification layer\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(self.bert_classifier.config.hidden_size * 2, num_labels)\n\n    def forward(self, input_ids, attention_mask):\n        # Pass through the first BERT encoder\n        encoder_outputs = self.bert_encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        encoder_cls = encoder_outputs.last_hidden_state[:,0,:]  # CLS token\n\n        # Pass through the second BERT classifier\n        classifier_outputs = self.bert_classifier(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        classifier_cls = classifier_outputs.last_hidden_state[:,0,:]  # CLS token\n\n        # Concatenate CLS tokens from both BERTs\n        combined = torch.cat((encoder_cls, classifier_cls), dim=1)\n        combined = self.dropout(combined)\n\n        # Final classification layer\n        logits = self.classifier(combined)\n\n        return logits\n","metadata":{"id":"4A2-53w04PS9","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:36:10.366835Z","iopub.execute_input":"2025-04-11T14:36:10.367190Z","iopub.status.idle":"2025-04-11T14:36:10.375390Z","shell.execute_reply.started":"2025-04-11T14:36:10.367153Z","shell.execute_reply":"2025-04-11T14:36:10.374465Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"\n# Check for GPU\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(f\"Using device: {device}\")\n\n# Initialize the model\nmodel = DoubleBERT()\nmodel.to(device)\n\n# Define optimizer\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n\n# Define number of training steps\nepochs = 3\ntotal_steps = len(train_loader) * epochs\n\n# Define scheduler\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)\n\n# Define loss function\ncriterion = nn.CrossEntropyLoss()\n","metadata":{"id":"YWc2MBGg4PQo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc370f73-b8ce-4b46-91d3-028a7af7965d","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:36:10.376557Z","iopub.execute_input":"2025-04-11T14:36:10.377217Z","iopub.status.idle":"2025-04-11T14:36:13.914214Z","shell.execute_reply.started":"2025-04-11T14:36:10.377174Z","shell.execute_reply":"2025-04-11T14:36:13.913489Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c03e240be9b24c90933d56b02eaa75c0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def train_epoch(model, data_loader, optimizer, scheduler, device, criterion):\n    model.train()\n    total_loss = 0\n    for batch in tqdm(data_loader, desc=\"Training\"):\n        optimizer.zero_grad()\n\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n        loss = criterion(outputs, labels)\n        total_loss += loss.item()\n\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n\n    avg_loss = total_loss / len(data_loader)\n    return avg_loss\n\ndef eval_model(model, data_loader, device, criterion):\n    model.eval()\n    total_loss = 0\n    preds = []\n    true_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n\n            _, predicted = torch.max(outputs, dim=1)\n            preds.extend(predicted.cpu().numpy())\n            true_labels.extend(labels.cpu().numpy())\n\n    avg_loss = total_loss / len(data_loader)\n    accuracy = accuracy_score(true_labels, preds)\n    report = classification_report(true_labels, preds, digits=4)\n    return avg_loss, accuracy, report\n","metadata":{"id":"dRBR4U2j4ly8","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:36:13.915343Z","iopub.execute_input":"2025-04-11T14:36:13.915876Z","iopub.status.idle":"2025-04-11T14:36:13.925078Z","shell.execute_reply.started":"2025-04-11T14:36:13.915836Z","shell.execute_reply":"2025-04-11T14:36:13.924211Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"for epoch in range(epochs):\n    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n    print(\"-\" * 20)\n\n    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device, criterion)\n    print(f\"Training Loss: {train_loss:.4f}\")\n\n    val_loss, val_accuracy, val_report = eval_model(model, val_loader, device, criterion)\n    print(f\"Validation Loss: {val_loss:.4f}\")\n    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n    print(\"Classification Report:\")\n    print(val_report)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"id":"7uK6SNjl4lvh","outputId":"cf5d1384-5800-4a0c-94f5-773179a99bb5","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:36:13.926415Z","iopub.execute_input":"2025-04-11T14:36:13.927284Z","iopub.status.idle":"2025-04-11T17:34:22.282053Z","shell.execute_reply.started":"2025-04-11T14:36:13.927218Z","shell.execute_reply":"2025-04-11T17:34:22.281224Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/3\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 4578/4578 [51:58<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.4058\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 1962/1962 [07:20<00:00,  4.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.3747\nValidation Accuracy: 0.8315\nClassification Report:\n              precision    recall  f1-score   support\n\n           0     0.8051    0.8741    0.8381     15667\n           1     0.8628    0.7891    0.8243     15724\n\n    accuracy                         0.8315     31391\n   macro avg     0.8339    0.8316    0.8312     31391\nweighted avg     0.8340    0.8315    0.8312     31391\n\n\nEpoch 2/3\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 4578/4578 [52:05<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.2705\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 1962/1962 [07:19<00:00,  4.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.4231\nValidation Accuracy: 0.8335\nClassification Report:\n              precision    recall  f1-score   support\n\n           0     0.8291    0.8393    0.8342     15667\n           1     0.8379    0.8276    0.8327     15724\n\n    accuracy                         0.8335     31391\n   macro avg     0.8335    0.8335    0.8335     31391\nweighted avg     0.8335    0.8335    0.8335     31391\n\n\nEpoch 3/3\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 4578/4578 [52:04<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.1610\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 1962/1962 [07:20<00:00,  4.46it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.6292\nValidation Accuracy: 0.8289\nClassification Report:\n              precision    recall  f1-score   support\n\n           0     0.8305    0.8258    0.8281     15667\n           1     0.8274    0.8320    0.8297     15724\n\n    accuracy                         0.8289     31391\n   macro avg     0.8289    0.8289    0.8289     31391\nweighted avg     0.8289    0.8289    0.8289     31391\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"class_counts = pd.Series(y).value_counts().sort_index()  # Adjust if using df directly\ntotal_samples = sum(class_counts)\nclass_weights = torch.tensor([total_samples / count for count in class_counts], dtype=torch.float32).to(device)\n\n# Define weighted cross-entropy loss\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n\n# Define optimizer\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n\n# Define number of training steps\nepochs = 3\ntotal_steps = len(train_loader) * epochs\n\n# Define scheduler\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)\n\ndef train_epoch(model, data_loader, optimizer, scheduler, device, criterion):\n    model.train()\n    total_loss = 0\n    for batch in tqdm(data_loader, desc=\"Training\"):\n        optimizer.zero_grad()\n\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n        loss = criterion(outputs, labels)\n        total_loss += loss.item()\n\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n\n    avg_loss = total_loss / len(data_loader)\n    return avg_loss\n\ndef eval_model(model, data_loader, device, criterion):\n    model.eval()\n    total_loss = 0\n    preds = []\n    true_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n\n            _, predicted = torch.max(outputs, dim=1)\n            preds.extend(predicted.cpu().numpy())\n            true_labels.extend(labels.cpu().numpy())\n\n    avg_loss = total_loss / len(data_loader)\n    accuracy = accuracy_score(true_labels, preds)\n    report = classification_report(true_labels, preds, digits=4)\n    return avg_loss, accuracy, report\n\nfor epoch in range(epochs):\n    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n    print(\"-\" * 20)\n\n    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device, criterion)\n    print(f\"Training Loss: {train_loss:.4f}\")\n\n    val_loss, val_accuracy, val_report = eval_model(model, val_loader, device, criterion)\n    print(f\"Validation Loss: {val_loss:.4f}\")\n    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n    print(\"Classification Report:\")\n    print(val_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:34:22.283590Z","iopub.execute_input":"2025-04-11T17:34:22.284119Z","execution_failed":"2025-04-12T14:51:25.010Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/3\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"Training:   1%|▏         | 60/4578 [00:40<51:15,  1.47it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Save the model\nmodel_save_path = 'double_bert_sarcasm_detector.pt'\ntorch.save(model.state_dict(), model_save_path)\nprint(f\"Model saved to {model_save_path}\")\n","metadata":{"id":"cMHfLmY14qWx","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# To load the model later\nmodel = DoubleBERT()\nmodel.load_state_dict(torch.load('double_bert_sarcasm_detector.pt'))\nmodel.to(device)\nmodel.eval()\n\n# Function to predict sarcasm\ndef predict_sarcasm(text, model, tokenizer, device, max_len=128):\n    encoding = tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=max_len,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, prediction = torch.max(outputs, dim=1)\n\n    return prediction.item()\n\n# Example usage\nsample_text = \"I just love getting stuck in traffic for hours!\"\nprediction = predict_sarcasm(sample_text, model, tokenizer, device)\nlabel = \"Sarcastic\" if prediction == 1 else \"Not Sarcastic\"\nprint(f\"Prediction: {label}\")\n","metadata":{"id":"2oBhcGp44qTX","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"id":"YkWbHn644qQ4","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def eval_model(model, data_loader, device, criterion):\n    model = model.eval()\n    val_loss = 0\n    correct_predictions = 0\n    val_preds = []\n    val_labels = []\n\n    with torch.no_grad():\n        for data in data_loader:\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            labels = data['labels'].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            # Get predictions\n            _, preds = torch.max(outputs, dim=1)\n\n            # Collect predictions and true labels\n            val_preds.extend(preds.cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n\n            correct_predictions += torch.sum(preds == labels)\n\n    # Calculate accuracy\n    val_accuracy = correct_predictions.double() / len(data_loader.dataset)\n\n    return val_loss / len(data_loader), val_accuracy, val_preds, val_labels\n","metadata":{"id":"6oKknA5WKNJU","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model\nval_loss, val_accuracy, val_preds, val_labels = eval_model(model, val_loader, device, criterion)\n","metadata":{"id":"4z26mpKIKNG0","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Validation Loss: {val_loss}\")\nprint(f\"Validation Accuracy: {val_accuracy}\")\n","metadata":{"id":"hda-DNqzMRU3","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(\"\\nClassification Report:\\n\", classification_report(val_labels, val_preds))\n","metadata":{"id":"nV-wwirCMULI","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(val_labels, val_preds)\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\nplt.title(\"Validation Confusion Matrix\")\nplt.ylabel('Actual Labels')\nplt.xlabel('Predicted Labels')\nplt.show()\n","metadata":{"id":"Pib66JBsMUIh","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support\n\nprecision, recall, f1, _ = precision_recall_fscore_support(val_labels, val_preds, average='weighted')\nprint(f\"Weighted Precision: {precision}\")\nprint(f\"Weighted Recall: {recall}\")\nprint(f\"Weighted F1 Score: {f1}\")\n","metadata":{"id":"oCztb4tZMUF9","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"false_negatives = [val_texts[i] for i, (pred, true) in enumerate(zip(val_preds, val_labels)) if pred == 0 and true == 1]\nfalse_positives = [val_texts[i] for i, (pred, true) in enumerate(zip(val_preds, val_labels)) if pred == 1 and true == 0]\n\nprint(\"Common False Negatives (sarcasm missed):\")\nfor text in false_negatives[:5]:\n    print(text)\n\nprint(\"\\nCommon False Positives (non-sarcastic classified as sarcastic):\")\nfor text in false_positives[:5]:\n    print(text)\n","metadata":{"id":"JQctfL0EMT9j","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nclass_f1_scores = f1_score(val_labels, val_preds, average=None)\nprint(f\"Class-wise F1-Scores: {class_f1_scores}\")\n","metadata":{"id":"TRCzByqqONPb","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.016Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def eval_model(model, data_loader, device, criterion):\n    model = model.eval()\n    val_loss = 0\n    correct_predictions = 0\n    val_preds = []\n    val_labels = []\n\n    with torch.no_grad():\n        for data in data_loader:\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            labels = data['labels'].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            # Get predictions\n            _, preds = torch.max(outputs, dim=1)\n\n            # Collect predictions and true labels\n            val_preds.extend(preds.cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n\n            correct_predictions += torch.sum(preds == labels).item()  # Ensure it's a Python number\n\n    # Calculate accuracy as a float\n    val_accuracy = correct_predictions / len(data_loader.dataset)  # This is now a float\n\n    return val_loss / len(data_loader), float(val_accuracy), val_preds, val_labels  # Ensure val_accuracy is a float\n","metadata":{"id":"M25Gx4nbO_XU","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_loss, val_accuracy, val_preds, val_labels = eval_model(model, val_loader, device, criterion)","metadata":{"id":"XKKHZVOpIl7K","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After your evaluation, you should have the following:\nval_loss, val_accuracy, val_preds, val_labels = eval_model(model, val_loader, device, criterion)\n\n# Define true_labels from your validation labels\ntrue_labels = val_labels\n\n# Convert predictions to probabilities (for binary classification)\n# Assuming you have a binary classification with outputs as logits\nval_preds_probs = [1 if pred == 1 else 0 for pred in val_preds]  # Modify based on your model's output\n\n# Plotting ROC and Precision-Recall curves\nplot_roc_curve(true_labels, val_preds_probs)\nplot_precision_recall_curve(true_labels, val_preds_probs)\n","metadata":{"id":"SWWXAbE-JaDo","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify lengths before plotting\nprint(f\"Length of train_losses: {len(train_losses)}\")\nprint(f\"Length of val_losses: {len(val_losses)}\")\nprint(f\"Length of val_accuracies: {len(val_accuracies)}\")\n","metadata":{"id":"-DOQE-_WI5bL","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. ROC Curve\ndef plot_roc_curve(true_labels, predictions):\n    fpr, tpr, _ = roc_curve(true_labels, predictions)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC Curve (area = {:.2f})'.format(roc_auc))\n    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')  # Diagonal line\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic')\n    plt.legend(loc='lower right')\n    plt.show()\n\n# 3. Precision-Recall Curve\ndef plot_precision_recall_curve(true_labels, predictions):\n    precision, recall, _ = precision_recall_curve(true_labels, predictions)\n    plt.figure(figsize=(10, 6))\n    plt.plot(recall, precision, color='green', lw=2)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.show()\n\n# Assuming your final validation predictions are in val_preds and true_labels\n# Convert val_preds to probabilities if necessary (e.g., for binary classification)\nval_preds_probs = [1 if pred == 1 else 0 for pred in val_preds]  # Modify based on your model's output\n\n# Plotting ROC and Precision-Recall curves\nplot_roc_curve(true_labels, val_preds_probs)\nplot_precision_recall_curve(true_labels, val_preds_probs)\n","metadata":{"id":"ijztpdKUkPJd","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.metrics import confusion_matrix\n\n# Extracting features and labels including attention mask\ndef extract_val_data(val_loader):\n    X_val = []\n    attention_masks = []\n    y_val = []\n    for data in val_loader:\n        input_ids = data['input_ids']  # Replace with your actual input features\n        attention_mask = data['attention_mask']\n        labels = data['labels'].numpy()\n\n        X_val.append(input_ids.cpu().numpy())  # Assuming input_ids is a tensor\n        attention_masks.append(attention_mask.cpu().numpy())  # Assuming attention_mask is a tensor\n        y_val.append(labels)\n\n    return np.concatenate(X_val), np.concatenate(attention_masks), np.concatenate(y_val)\n\n# Get validation data\nX_val, attention_masks, y_val = extract_val_data(val_loader)\n\n# Assuming you have already made predictions with your model\n# y_pred = model.predict(X_val)  # Or however you obtain your predictions\n# If you use PyTorch:\nmodel.eval()\nwith torch.no_grad():\n    inputs = torch.tensor(X_val).to(device)  # Move to device if needed\n    masks = torch.tensor(attention_masks).to(device)  # Move attention masks to device\n\n    # Pass both input_ids and attention_mask to the model\n    outputs = model(input_ids=inputs, attention_mask=masks)\n    _, y_pred = torch.max(outputs, 1)\n    y_pred = y_pred.cpu().numpy()  # Convert to NumPy for further processing\n\n# Continue with the rest of your code...\n\n\n# 1. Permutation Importance\ndef plot_permutation_importance(model, X_val, y_val):\n    result = permutation_importance(model, X_val, y_val, n_repeats=30, random_state=42, n_jobs=-1)\n    sorted_idx = result.importances_mean.argsort()\n\n    plt.figure(figsize=(10, 6))\n    plt.barh(range(len(sorted_idx)), result.importances_mean[sorted_idx], yerr=result.importances_std[sorted_idx])\n    plt.yticks(range(len(sorted_idx)), np.array(X_val.columns)[sorted_idx])  # Adjust for DataFrame or array\n    plt.title(\"Permutation Importance\")\n    plt.xlabel(\"Importance Score\")\n    plt.show()\n\n# Example call:\nplot_permutation_importance(model, X_val, y_val)\n\n# 2. Class Distribution\ndef plot_class_distribution(y):\n    sns.countplot(x=y)\n    plt.title(\"Class Distribution\")\n    plt.xlabel(\"Class\")\n    plt.ylabel(\"Count\")\n    plt.show()\n\n# Example call:\nplot_class_distribution(y_val)\n\n# 3. Misclassification Plots\ndef plot_misclassified_samples(X_val, y_val, y_pred, n_samples=10):\n    misclassified_idx = np.where(y_val != y_pred)[0]\n    if len(misclassified_idx) == 0:\n        print(\"No misclassifications found.\")\n        return\n\n    # Select a few misclassified samples\n    np.random.shuffle(misclassified_idx)\n    misclassified_idx = misclassified_idx[:n_samples]\n\n    plt.figure(figsize=(15, 5))\n    for i, idx in enumerate(misclassified_idx):\n        plt.subplot(2, n_samples // 2, i + 1)\n        plt.imshow(X_val[idx], cmap='gray')  # Adjust based on your data format\n        plt.title(f'True: {y_val[idx]}\\nPredicted: {y_pred[idx]}')\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# Example call:\nplot_misclassified_samples(X_val, y_val, y_pred)\n","metadata":{"id":"6oNze4_skSdw","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_class_distribution(true_labels):\n    plt.figure(figsize=(8, 5))\n    sns.countplot(x=true_labels)\n    plt.title('Class Distribution in Validation Set')\n    plt.xlabel('Classes')\n    plt.ylabel('Count')\n    plt.show()\n\n# Call the function\nplot_class_distribution(true_labels)\n\n# Analyzing Misclassifications\ndef analyze_misclassifications(true_labels, val_preds):\n    misclassified = [(true, pred) for true, pred in zip(true_labels, val_preds) if true != pred]\n    print(\"Misclassifications:\")\n    for true, pred in misclassified[:10]:  # Print the first 10 misclassifications\n        print(f\"True: {true}, Predicted: {pred}\")\n\n# Call the function\nanalyze_misclassifications(true_labels, val_preds)\n","metadata":{"id":"k7pH7hkskSXQ","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Misclassification Plots\ndef plot_misclassified_samples(X_val, y_val, y_pred, n_samples=10):\n    misclassified_idx = np.where(y_val != y_pred)[0]\n    if len(misclassified_idx) == 0:\n        print(\"No misclassifications found.\")\n        return\n\n    # Select a few misclassified samples\n    np.random.shuffle(misclassified_idx)\n    misclassified_idx = misclassified_idx[:n_samples]\n    print(misclassified_idx)\n    plt.figure(figsize=(15, 5))\n    for i, idx in enumerate(misclassified_idx):\n        plt.subplot(2, n_samples // 2, i + 1)\n        plt.imshow(X_val[idx], cmap='gray')  # Adjust based on your data format\n        plt.title(f'True: {y_val[idx]}\\nPredicted: {y_pred[idx]}')\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# Example call:\nplot_misclassified_samples(X_val, y_val, y_pred)","metadata":{"id":"TX98g9NFkST3","trusted":true,"execution":{"execution_failed":"2025-04-12T14:51:25.018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"3zxWA7LVL34Q","trusted":true},"outputs":[],"execution_count":null}]}